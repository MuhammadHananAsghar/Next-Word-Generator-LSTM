{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Next Word Generator(LSTM).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghS750oPFKtJ",
        "outputId": "6fe61eb8-72f2-42c9-94d0-0805b12e778e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jan 17 09:33:33 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "dwKDl54DJ-zH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7b5653c-32c0-4c5b-cbc0-3cef947d7688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"datastore.pkl\", \"rb\") as fl:\n",
        "  datastore = pickle.load(fl)"
      ],
      "metadata": {
        "id": "hkz1oXv8UhR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total Lines: {len(datastore)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObpvYxYnVE87",
        "outputId": "7a9b73b7-8290-46c7-ee43-c8e4361819b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Lines: 54534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datastore = [str(line) for line in datastore[:500]]"
      ],
      "metadata": {
        "id": "HGAcRM6PVy1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total Lines: {len(datastore)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyACgqA8Y_az",
        "outputId": "8c547730-d27e-49b3-b169-9926d21c4acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Lines: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(datastore)"
      ],
      "metadata": {
        "id": "RHR2Pw7kVO5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_words = len(tokenizer.word_index)+1\n",
        "print(\"Vocabulary Size: \", total_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsXtLAd0Vk1l",
        "outputId": "c0a2a5ee-80d6-4071-ed5c-10c4f80985f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size:  9608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for line in datastore:\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1, len(token_list)):\n",
        "    n_gram_sequence = token_list[:i+1]\n",
        "    input_sequences.append(n_gram_sequence)"
      ],
      "metadata": {
        "id": "Xv2iSnurWKXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total Number of Sequences: {len(input_sequences)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2WMOwyBWs0_",
        "outputId": "dd8a2daa-635f-4862-aeed-651d1233ae4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of Sequences: 44981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max([len(line) for line in input_sequences])\n",
        "print(f\"Maximum Length of Sentence: {max_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAJv53I7Wxp6",
        "outputId": "8baa2e1f-60ac-43a9-9319-94d662354927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum Length of Sentence: 306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_length, padding='pre'))"
      ],
      "metadata": {
        "id": "9lIvmh2aXD0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs = input_sequences[:,:-1]\n",
        "labels = input_sequences[:, -1]"
      ],
      "metadata": {
        "id": "fj2Yay6jXD4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(xs), len(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI4CQ3m5YQnE",
        "outputId": "e8278a77-53a0-4a35-c755-28bb7b6a0185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44981 44981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "metadata": {
        "id": "YH16x70jYT3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Embedding(total_words, 240, input_length=max_length-1),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100, return_sequences=True)),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(total_words, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHbojt8FZLKJ",
        "outputId": "67eca7f2-fc8b-4bc7-8689-6c61f0baac26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 305, 240)          2305920   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 305, 200)         272800    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 64)               59648     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               6500      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 9608)              970408    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,615,276\n",
            "Trainable params: 3,615,276\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(xs, ys, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ovd1wgfZx6X",
        "outputId": "65961a50-e686-4c21-8dae-aa07070bf9a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1406/1406 [==============================] - 74s 46ms/step - loss: 7.4869 - accuracy: 0.0697\n",
            "Epoch 2/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 6.9783 - accuracy: 0.0827\n",
            "Epoch 3/100\n",
            "1406/1406 [==============================] - 65s 46ms/step - loss: 6.6859 - accuracy: 0.1043\n",
            "Epoch 4/100\n",
            "1406/1406 [==============================] - 65s 46ms/step - loss: 6.4558 - accuracy: 0.1197\n",
            "Epoch 5/100\n",
            "1406/1406 [==============================] - 65s 46ms/step - loss: 6.2465 - accuracy: 0.1289\n",
            "Epoch 6/100\n",
            "1406/1406 [==============================] - 65s 46ms/step - loss: 6.0440 - accuracy: 0.1371\n",
            "Epoch 7/100\n",
            "1406/1406 [==============================] - 65s 46ms/step - loss: 5.8467 - accuracy: 0.1466\n",
            "Epoch 8/100\n",
            "1406/1406 [==============================] - 65s 46ms/step - loss: 5.6548 - accuracy: 0.1551\n",
            "Epoch 9/100\n",
            "1406/1406 [==============================] - 65s 46ms/step - loss: 5.4744 - accuracy: 0.1644\n",
            "Epoch 10/100\n",
            "1406/1406 [==============================] - 65s 46ms/step - loss: 5.3022 - accuracy: 0.1720\n",
            "Epoch 11/100\n",
            "1406/1406 [==============================] - 65s 46ms/step - loss: 5.1291 - accuracy: 0.1800\n",
            "Epoch 12/100\n",
            "1406/1406 [==============================] - 65s 46ms/step - loss: 4.9641 - accuracy: 0.1891\n",
            "Epoch 13/100\n",
            "1406/1406 [==============================] - 65s 46ms/step - loss: 4.8017 - accuracy: 0.1998\n",
            "Epoch 14/100\n",
            "1406/1406 [==============================] - 66s 47ms/step - loss: 4.6452 - accuracy: 0.2100\n",
            "Epoch 15/100\n",
            "1406/1406 [==============================] - 65s 46ms/step - loss: 4.4934 - accuracy: 0.2218\n",
            "Epoch 16/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 4.3385 - accuracy: 0.2337\n",
            "Epoch 17/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 4.1953 - accuracy: 0.2457\n",
            "Epoch 18/100\n",
            "1406/1406 [==============================] - 65s 46ms/step - loss: 4.0511 - accuracy: 0.2565\n",
            "Epoch 19/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 3.9145 - accuracy: 0.2702\n",
            "Epoch 20/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 3.7806 - accuracy: 0.2838\n",
            "Epoch 21/100\n",
            "1406/1406 [==============================] - 64s 45ms/step - loss: 3.6460 - accuracy: 0.2984\n",
            "Epoch 22/100\n",
            "1406/1406 [==============================] - 65s 46ms/step - loss: 3.5204 - accuracy: 0.3135\n",
            "Epoch 23/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 3.3879 - accuracy: 0.3315\n",
            "Epoch 24/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 3.2695 - accuracy: 0.3470\n",
            "Epoch 25/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 3.1457 - accuracy: 0.3654\n",
            "Epoch 26/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 3.0257 - accuracy: 0.3792\n",
            "Epoch 27/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 2.9176 - accuracy: 0.3962\n",
            "Epoch 28/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 2.8127 - accuracy: 0.4122\n",
            "Epoch 29/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 2.7062 - accuracy: 0.4306\n",
            "Epoch 30/100\n",
            "1406/1406 [==============================] - 65s 46ms/step - loss: 2.6100 - accuracy: 0.4447\n",
            "Epoch 31/100\n",
            "1406/1406 [==============================] - 65s 46ms/step - loss: 2.5240 - accuracy: 0.4613\n",
            "Epoch 32/100\n",
            "1406/1406 [==============================] - 65s 46ms/step - loss: 2.4218 - accuracy: 0.4779\n",
            "Epoch 33/100\n",
            "1406/1406 [==============================] - 65s 46ms/step - loss: 2.3344 - accuracy: 0.4937\n",
            "Epoch 34/100\n",
            "1406/1406 [==============================] - 65s 46ms/step - loss: 2.2475 - accuracy: 0.5095\n",
            "Epoch 35/100\n",
            "1406/1406 [==============================] - 66s 47ms/step - loss: 2.1668 - accuracy: 0.5236\n",
            "Epoch 36/100\n",
            "1406/1406 [==============================] - 66s 47ms/step - loss: 2.0940 - accuracy: 0.5370\n",
            "Epoch 37/100\n",
            "1406/1406 [==============================] - 66s 47ms/step - loss: 2.0093 - accuracy: 0.5525\n",
            "Epoch 38/100\n",
            "1406/1406 [==============================] - 65s 47ms/step - loss: 1.9403 - accuracy: 0.5654\n",
            "Epoch 39/100\n",
            "1406/1406 [==============================] - 66s 47ms/step - loss: 1.8749 - accuracy: 0.5782\n",
            "Epoch 40/100\n",
            "1406/1406 [==============================] - 65s 46ms/step - loss: 1.8082 - accuracy: 0.5908\n",
            "Epoch 41/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 1.7373 - accuracy: 0.6061\n",
            "Epoch 42/100\n",
            "1406/1406 [==============================] - 64s 45ms/step - loss: 1.6768 - accuracy: 0.6177\n",
            "Epoch 43/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 1.6126 - accuracy: 0.6318\n",
            "Epoch 44/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 1.5552 - accuracy: 0.6409\n",
            "Epoch 45/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 1.5111 - accuracy: 0.6513\n",
            "Epoch 46/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 1.4384 - accuracy: 0.6665\n",
            "Epoch 47/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 1.3922 - accuracy: 0.6778\n",
            "Epoch 48/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 1.3458 - accuracy: 0.6822\n",
            "Epoch 49/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 1.2991 - accuracy: 0.6946\n",
            "Epoch 50/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 1.2438 - accuracy: 0.7091\n",
            "Epoch 51/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 1.2054 - accuracy: 0.7159\n",
            "Epoch 52/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 1.1648 - accuracy: 0.7245\n",
            "Epoch 53/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 1.1249 - accuracy: 0.7313\n",
            "Epoch 54/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 1.0855 - accuracy: 0.7412\n",
            "Epoch 55/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 1.0466 - accuracy: 0.7502\n",
            "Epoch 56/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 1.0137 - accuracy: 0.7574\n",
            "Epoch 57/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.9748 - accuracy: 0.7656\n",
            "Epoch 58/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.9310 - accuracy: 0.7761\n",
            "Epoch 59/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.9059 - accuracy: 0.7818\n",
            "Epoch 60/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.8918 - accuracy: 0.7845\n",
            "Epoch 61/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.8619 - accuracy: 0.7897\n",
            "Epoch 62/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.8212 - accuracy: 0.8012\n",
            "Epoch 63/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.8011 - accuracy: 0.8060\n",
            "Epoch 64/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.7812 - accuracy: 0.8099\n",
            "Epoch 65/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.7448 - accuracy: 0.8173\n",
            "Epoch 66/100\n",
            "1406/1406 [==============================] - 65s 46ms/step - loss: 0.7391 - accuracy: 0.8198\n",
            "Epoch 67/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.7123 - accuracy: 0.8232\n",
            "Epoch 68/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.6823 - accuracy: 0.8316\n",
            "Epoch 69/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.6592 - accuracy: 0.8390\n",
            "Epoch 70/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.6405 - accuracy: 0.8411\n",
            "Epoch 71/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.6280 - accuracy: 0.8467\n",
            "Epoch 72/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.6163 - accuracy: 0.8470\n",
            "Epoch 73/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.5864 - accuracy: 0.8546\n",
            "Epoch 74/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.5696 - accuracy: 0.8586\n",
            "Epoch 75/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.5557 - accuracy: 0.8623\n",
            "Epoch 76/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.5509 - accuracy: 0.8637\n",
            "Epoch 77/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.5367 - accuracy: 0.8672\n",
            "Epoch 78/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.5098 - accuracy: 0.8717\n",
            "Epoch 79/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.4945 - accuracy: 0.8776\n",
            "Epoch 80/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.4873 - accuracy: 0.8772\n",
            "Epoch 81/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.4887 - accuracy: 0.8782\n",
            "Epoch 82/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.4652 - accuracy: 0.8837\n",
            "Epoch 83/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.4422 - accuracy: 0.8900\n",
            "Epoch 84/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.4341 - accuracy: 0.8909\n",
            "Epoch 85/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.4210 - accuracy: 0.8957\n",
            "Epoch 86/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.4244 - accuracy: 0.8948\n",
            "Epoch 87/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.4103 - accuracy: 0.8972\n",
            "Epoch 88/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.3967 - accuracy: 0.9026\n",
            "Epoch 89/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.3829 - accuracy: 0.9034\n",
            "Epoch 90/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.3826 - accuracy: 0.9048\n",
            "Epoch 91/100\n",
            "1406/1406 [==============================] - 64s 45ms/step - loss: 0.4082 - accuracy: 0.8982\n",
            "Epoch 92/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.3583 - accuracy: 0.9118\n",
            "Epoch 93/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.3253 - accuracy: 0.9187\n",
            "Epoch 94/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.3278 - accuracy: 0.9185\n",
            "Epoch 95/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.3463 - accuracy: 0.9127\n",
            "Epoch 96/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.3463 - accuracy: 0.9123\n",
            "Epoch 97/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.3180 - accuracy: 0.9217\n",
            "Epoch 98/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.3146 - accuracy: 0.9210\n",
            "Epoch 99/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.3255 - accuracy: 0.9176\n",
            "Epoch 100/100\n",
            "1406/1406 [==============================] - 64s 46ms/step - loss: 0.3127 - accuracy: 0.9221\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/Models(AI)/next_w_g.h5\")"
      ],
      "metadata": {
        "id": "ouvyX05sZ5A1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rgGB3ZdOzk-R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}